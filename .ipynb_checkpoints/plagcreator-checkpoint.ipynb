{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#text modes\n",
    "class Text_mode(Enum):\n",
    "    simple = 0\n",
    "    markov = 1\n",
    "    \n",
    "#plag modes\n",
    "class Plag_mode(Enum):\n",
    "    one_to_one = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parses a wiki dump textfile\n",
    "return: dictionary with key: title of wiki article and value: text of wiki article as list of words\n",
    "'''\n",
    "def parse_wiki_dump():\n",
    "    source_file = \"dump/clean_dump.xml\"\n",
    "    \n",
    "    text_file = open(source_file, \"r\")\n",
    "    wiki = text_file.read() #whole file in a string\n",
    "    text_file.close()\n",
    "\n",
    "    texts = wiki.split(\"-------------------------------------------------\") #split file at each separator line\n",
    "    texts = [re.sub(r'==.*==','',x) for x in texts] #remove section headings\n",
    "    texts = [re.sub(r'[^\\w]|\\n|[\\s]',' ',x) for x in texts] #remove punctuation chars\n",
    "    #texts = [re.sub(r'\\d+','',x) for x in texts] #remove numbers\n",
    "    texts = [re.sub(r'\\s{2,}',' ',x).strip() for x in texts] #replace multiple space chars with one space char\n",
    "    texts = [x for x in texts if x != ''] #remove empty strings from list\n",
    "    texts = {texts[i]: texts[i+1].split(' ') for i in range(0, len(texts), 2)} #turn list into a dictionary\n",
    "    return texts\n",
    "\n",
    "wiki_articles = parse_wiki_dump() #parse only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generates a list of words and dictionary for the markov chain text generator\n",
    "return: tuple with list of words and dictionary\n",
    "'''\n",
    "def make_words_list_and_db():\n",
    "    #concat all texts of all wiki articles as one bisg list of words\n",
    "    words = []\n",
    "    for text in wiki_articles.values():\n",
    "        words.append(text)\n",
    "    words = sum(words, []) #flatten\n",
    "    \n",
    "    #build triples of three succeeding words with a step size of 1\n",
    "    triples = []\n",
    "    if len(words) >= 3:\n",
    "        for i in range(len(words) - 2):\n",
    "            triple = (words[i], words[i + 1], words[i + 2])\n",
    "            triples.append(triple)\n",
    "    \n",
    "    #build a dictionary with a two word key and a list with all succeeding words as the value\n",
    "    db = dict()\n",
    "    for w1, w2, w3 in triples:\n",
    "        key = (w1, w2)\n",
    "        if key in db:\n",
    "            db[key].append(w3)\n",
    "        else:\n",
    "            db[key] = [w3]\n",
    "    return (words, db)\n",
    "\n",
    "words, db = make_words_list_and_db() #make words list and db only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generates a random text out of a list of words\n",
    "param number_of_texts: number of texts to be generated\n",
    "param min_length: min length of the text (lower limit of a random length)\n",
    "param max_length: max length of the text (upper limit of a random length)\n",
    "return: list of generated texts; a text is represented as list of words\n",
    "'''\n",
    "def text_generator_simple(number_of_texts, min_length, max_length):\n",
    "    source_file = \"wortliste/germanWords.txt\"\n",
    "    \n",
    "    text_file = open(source_file, \"r\")\n",
    "    words = text_file.read().splitlines() #read lines of file to list\n",
    "    text_file.close()\n",
    "    \n",
    "    random_texts = [] #list with texts\n",
    "    for x in range(number_of_texts):\n",
    "        length = random.randrange(min_length, max_length)\n",
    "        text = []\n",
    "        for y in range(length):\n",
    "            text.append(random.choice(words)) #randomly choosing words\n",
    "        random_texts.append(text)\n",
    "    return random_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generates a random text using markov chain. The generated text looks more natural\n",
    "param number_of_texts: number of texts to be generated\n",
    "param min_length: min length of the text (lower limit of a random length)\n",
    "param max_length: max length of the text (upper limit of a random length)\n",
    "return: list of generated texts; a text is represented as list of words\n",
    "'''\n",
    "def text_generator_markov(number_of_texts, min_length, max_length):    \n",
    "    random_texts = []\n",
    "    for x in range(number_of_texts):\n",
    "        seed_index = random.randrange(0, len(words) - 3) #randomly choose the index of the word to start with (seed)\n",
    "        w1, w2 = words[seed_index], words[seed_index + 1] #get this word and the next word from the dictionary\n",
    "        text = []\n",
    "        length = random.randrange(min_length, max_length)\n",
    "        for i in range(length):\n",
    "            text.append(w1)\n",
    "            w1, w2 = w2, random.choice(db[(w1, w2)]) #randomly choose one possible word for the selected key\n",
    "        text.append(w2)\n",
    "        random_texts.append(text)\n",
    "    \n",
    "    return random_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Randomly chooses a text part out of a wiki article\n",
    "param length: length of the plagiarized text part\n",
    "return: tuple (title of article, text part as list of words)\n",
    "'''\n",
    "def get_plag_text(length):\n",
    "    article_title = random.choice(list(wiki_articles.keys())) #randomly choose a wiki article\n",
    "    start = random.randrange(0,len(wiki_articles[article_title]) - length) #randomly choose start position of plag\n",
    "    \n",
    "    plag = wiki_articles[article_title][start : start + length] #cut text part out\n",
    "\n",
    "    return (article_title, plag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generates texts with embedded plagiarism + info file for each text and outputs them to txt files\n",
    "param number_of_texts: number of texts to be generated\n",
    "param min_text_length: min length of the surrounding text (lower limit of a random length)\n",
    "param max_text_length: max length of the surrounding text (upper limit of a random length)\n",
    "param plag_length: length of the plagiarized text part\n",
    "param output_dir: output directory for the generated texts\n",
    "'''\n",
    "def generate_plags(text_mode, number_of_texts, min_text_length, max_text_length, plag_length, output_dir, ):\n",
    "    if text_mode == Text_mode.simple:\n",
    "        random_texts = text_generator_simple(number_of_texts, min_text_length, max_text_length)\n",
    "    elif text_mode == Text_mode.markov:\n",
    "        random_texts = text_generator_markov(number_of_texts, min_text_length, max_text_length)\n",
    "    else:\n",
    "        print(\"NO SUCH TEXT MODE (\" + str(text_mode) + \")!\")\n",
    "        return\n",
    "    \n",
    "    plag_texts = []\n",
    "    \n",
    "    i = 0 #index for file names\n",
    "    for text in random_texts:\n",
    "        plag_start = random.randrange(0, len(text)-1) #position of plag in surrounding text\n",
    "        plag = get_plag_text(plag_length) #randomly choose plag\n",
    "        text[plag_start : plag_start] = plag[1] #insert plag into surrounding text\n",
    "        plag_text = ' '.join(text) #convert list of words int space separated string\n",
    "        \n",
    "        #print info\n",
    "        print(\"text_length: \" + str(len(text)))\n",
    "        print(\"plagiarized_article: \" + plag[0])\n",
    "        print(\"plagiarism_start: \" + str(plag_start))\n",
    "        print(\"plagiarism_end: \" + str(plag_start + len(plag[1])-1))\n",
    "        print(\"plagiarism_length: \" + str(plag_length))\n",
    "        print(\"plagiarism_text_part:\\n\" + ' '.join(plag[1]))\n",
    "        print(\"text_with_plagiarism:\\n\" + plag_text)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #write text to file\n",
    "        output_file_name = output_dir + \"/plag\" + str(i) +\".txt\"\n",
    "        output_file = open(output_file_name, \"w\")\n",
    "        output_file.write(plag_text)\n",
    "        output_file.close()\n",
    "        \n",
    "        #write info file\n",
    "        output_file_name = output_dir + \"/plag\" + str(i) +\"_info.txt\"\n",
    "        output_file = open(output_file_name, \"w\")\n",
    "        output_file.write(\"text_length: \" + str(len(text)) + \"\\n\")\n",
    "        output_file.write(\"plagiarized_article: \" + plag[0] + \"\\n\")\n",
    "        output_file.write(\"plagiarism_start: \" + str(plag_start) + \"\\n\")\n",
    "        output_file.write(\"plagiarism_end: \" + str(plag_start + len(plag[1])) + \"\\n\")\n",
    "        output_file.write(\"plagiarism_length: \" + str(plag_length) + \"\\n\")\n",
    "        output_file.write(\"plagiarism_text_part: \" + ' '.join(plag[1]))\n",
    "        output_file.close()\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_length: 251\n",
      "plagiarized_article: Chemiestudium\n",
      "plagiarism_start: 26\n",
      "plagiarism_end: 45\n",
      "plagiarism_length: 20\n",
      "plagiarism_text_part:\n",
      "der Anteil der stellensuchenden promovierten Chemiker laut GDCh bei 8 2014 bei 13 Das Chemiestudium zeichnet sich durch eine Vielzahl\n",
      "text_with_plagiarism:\n",
      "oder Kartentools anzuzeigen oder aufzunehmen hat Der Preis wurde von der IUCN International Union for Conservation of Nature Cambridge University Press New York NY u a der Anteil der stellensuchenden promovierten Chemiker laut GDCh bei 8 2014 bei 13 Das Chemiestudium zeichnet sich durch eine Vielzahl durch die Vision seiner Eurydike Gretchen Täuscht mich ein entzückend Bild als auch im Chemielabor angewendet werden konnte ob es Fotografien lebender Exemplare gibt Einzig Aufnahmen von 12 756 274 Kilometern Die Länge inkl Schwanz betrug beim Männchen unter der Leitung Struktur breitet sich eine Melusine ähnelnde Figur eine Sirene mit doppeltem Fischschwanz als Firmenlogo von Starbucks Mélusine ist auch im Film durch einen eindeutigen Schlüssel identifiziert werden können die Vollblüter manchmal in der Dämmerung und der Bestseller Autor John Naisbitt Im Jahr 1899 erhielt Otto Voges S 14 19 Marcel Feige Der Abräumer Ein Gespräch mit Andreas Eschbach In Sascha Mamczak Wolfgang Jeschke Das Science Museum die Difference Engine No 2 Maschine liegen umfangreiche Belege über die Stadt Peine den Herzberg ein Hügel im Norden bis zur ersten Hochschule welche in der Schweiz Auch das Gewerbe das Kunststoffe unter Zusatz von Pigmenten und Füllstoffen in Deutschland und Israel mit Lea Fleischmann in einem Gebäude in der Lage der nationalen Integrität durch ein Atom mit gleichem Namen wurde in den Andenregionen Südamerikas und war Schwiegervater des Präsidenten In Der Social Demokrat Berlin Nr 16 17 August 1843 schrieb Bei Rösing war ich gestern dagegen vorgestern Abend Gestern Morgen hab ich doch die substantz der so\n",
      "\n",
      "\n",
      "text_length: 319\n",
      "plagiarized_article: Universidad San Francisco de Quito\n",
      "plagiarism_start: 141\n",
      "plagiarism_end: 160\n",
      "plagiarism_length: 20\n",
      "plagiarism_text_part:\n",
      "damals 130 eingeschriebenen Studenten Im Jahr 2012 hat sie ca 4000 undergraduate Studenten und 430 postgraduate Der Sitz der privaten\n",
      "text_with_plagiarism:\n",
      "Bathory Die Blutgräfin und bluttrinkenden Vampiren wurde erstmals zu Beginn des 20 Jahrhunderts einen Namen und konkrete Attributwerte haben Konzepte können Kind Konzepte eines Konzepts Die Ähnlichkeitswerte dieses Konzepts gegenüber allen anderen Theorien ist dass nicht jede Kriegshandlung innerhalb eines Shell Skripts unter DOS und Windows lässt sich mögen 2008 gefolgt von Myanmar Afghanistan Turkmenistan Usbekistan und Iran Viele Länder in diesem Zusammenhang ist die Bezeichnung Geopolitik bei ihnen noch nicht entdeckt wurden Die Überlochungen gingen in die Karte in einem zweiten Kreis mit 360 Das Wort Informatik wird dieses Datum auch noch im Jahr 2005 erklärte Ryōji Noyori 2001 gestiftet worden und wird 2016 geschlossen um dem Rüssel zu entgehen 1924 verschwand er spurlos Von der Carbidfabrik zu Chemiepark Klartext Verlag Essen 2012 S 4 Georg Fein 8 Juni 1998 starb Maria Reiche In Peru angekommen wurden Lisperguer und seine damals 130 eingeschriebenen Studenten Im Jahr 2012 hat sie ca 4000 undergraduate Studenten und 430 postgraduate Der Sitz der privaten Gruppe gelangten Ende 1708 auf der Insel Borneo gelegen sind wo Tiger im Kaukasus Turkmenistan im Norden der Insel Iriomote der südlichsten der Ryūkyū Inseln heimisch ist Inzwischen geht man in Nordeuropa und den Luftangriffen auf Hannover im Zweiten Weltkrieg für die russischen Mathematiker Alexei Sossinski und Wassiljew Boris Feigin Sabir Gusein Zade Juli Iljaschenko Yulij Ilyashenko Michail Zfasman Sergei Lando Igor Kritschewer Stefan Nemirowski Wiktor Prasolow Alexander Schen E B Idahosa der Sohn von August Wilhelm von Steuben und anderen Automaten zurück in denen ein Boot geborgen wird Bergen von Sikkim erbeuten sie in einem wissenschaftlichen Artikel Der Artikel entstand in Zusammenarbeit mit Frankreich fanden 1963 anlässlich der Silberhochzeit von König Georg II in London vor und nachdem sie bereits Thema in Deutschland Band 3 Dietz Verlag Berlin 2016 S 48 51 Bender Harold S 1957 Graeff op den Graeff 1610 1656 heiratete Eva von der Fallstelle flüchtet Darüber hinaus sind Jaguare in Mittelamerika gegründet In Augenblicke\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_plags(Text_mode.markov, 2, 200, 300, 20, \"plagiate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "#ggf. Zahlen rausfiltern\n",
    "#ggf. alles kleingeschrieben (mehr Kombinationsmöglichkeiten bei Markov)\n",
    "#mehrere Plagiate in einem Text\n",
    "#nicht nur 1 zu 1 Plagiate, sondern auch z.B. Wörter getauscht oder ersetzt\n",
    "#Plagiate auch in zufälliger Länge (min, max)\n",
    "#Ordner englisch benennen\n",
    "#ValueError tritt manchmal auf. Beheben! (siehe Screenshot)\n",
    "    #Mögliche Ursache: ggf. gibt es Wiki-Artikel, die kürzer als die geforderte Plagiat-Länge sind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screenshot ValueError\n",
    "<img src=\"ValueError.png\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
